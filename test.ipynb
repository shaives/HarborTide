{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import requests\n",
    "\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elevations(bases_geo_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Pulls elevation data from open-elevation.com\n",
    "\n",
    "            Parameters:\n",
    "                        bases_geo_df (DataFrame): Latitude and Longitude of each base\n",
    "\n",
    "            Returns:\n",
    "                        elevations_df (DataFrame): location and elevation of each base \n",
    "    \"\"\"\n",
    "    \n",
    "    elevations = list()\n",
    "\n",
    "    for lat, long in bases_geo_df['geoPoint'].values:\n",
    "\n",
    "        location = (f\"{lat},{long}\")\n",
    "        \n",
    "        url = f\"https://api.open-elevation.com/api/v1/lookup?locations={location}\"\n",
    "        \n",
    "        try:\n",
    "\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'results' in data and data['results']:\n",
    "\n",
    "                elevation = data['results'][0]['elevation']\n",
    "                elevations.append(elevation)\n",
    "\n",
    "            else:\n",
    "\n",
    "                elevations.append(None)\n",
    "            \n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "            elevations.append(None)\n",
    "            \n",
    "    elevations_df = pd.DataFrame({'elevation': elevations})  \n",
    "\n",
    "    elevations_df = pd.concat([bases_geo_df, elevations_df], axis=1)\n",
    "\n",
    "    return elevations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_bases(states = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a cleaned dataframe with all the military installations.\n",
    "\n",
    "            Parameters:\n",
    "                        states (list): list of states whose bases you want to see\n",
    "\n",
    "            Data:\n",
    "                        https://public.opendatasoft.com/explore/dataset/military-bases/export/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6Im1pbGl0YXJ5LWJhc2VzIiwib3B0aW9ucyI6e319LCJjaGFydHMiOlt7ImFsaWduTW9udGgiOnRydWUsInR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJvYmplY3RpZF8xIiwic2NpZW50aWZpY0Rpc3BsYXkiOnRydWUsImNvbG9yIjoiI0ZGNTE1QSJ9XSwieEF4aXMiOiJjb21wb25lbnQiLCJtYXhwb2ludHMiOjUwLCJzb3J0IjoiIn1dLCJ0aW1lc2NhbGUiOiIiLCJkaXNwbGF5TGVnZW5kIjp0cnVlLCJhbGlnbk1vbnRoIjp0cnVlfQ%3D%3D&location=6,37.78808,-111.09375&basemap=jawg.light\n",
    "\n",
    "            Returns:\n",
    "                        bases_df (DataFrame): \n",
    "    \"\"\"\n",
    "\n",
    "    # Choose columns we need\n",
    "    data_columns = ['Geo Point', 'COMPONENT', 'Site Name', 'State Terr', 'Oper Stat']\n",
    "\n",
    "    # read in all of the military bases - seperator ';'\n",
    "    bases_df = pd.read_csv('./data/military-bases.csv', sep=';', usecols = data_columns )\n",
    "\n",
    "    # rename columns for easier use\n",
    "    bases_df.rename(columns={'Geo Point': 'geoPoint', 'COMPONENT': \"component\", 'Site Name': 'name', 'State Terr': 'state', 'Oper Stat': 'status'}, inplace = True)\n",
    "\n",
    "    # checking that there is only Active and Inactive\n",
    "    #bases_df[(bases_df.status != 'Active') & (bases_df.status != 'Inactive')]\n",
    "\n",
    "    # drop all Inactive bases\n",
    "    bases_df = bases_df[bases_df.status != 'Inactive']\n",
    "\n",
    "    # convert geo points\n",
    "    bases_df[['latitude', 'longitude']] = bases_df['geoPoint'].str.split(',', expand = True).astype('float64')\n",
    "    bases_df['geoPoint'] = list(zip(bases_df['latitude'], bases_df['longitude']))\n",
    "    bases_df.drop(columns = ['latitude', 'longitude'], inplace =  True)\n",
    "\n",
    "    # filter by list of states\n",
    "    bases_df = bases_df[bases_df.state.isin(states)]\n",
    "\n",
    "    bases_df.reset_index(drop = True, inplace = True)   \n",
    "    \n",
    "    # get elevation for each location \n",
    "    bases_df = get_elevations(bases_df)   \n",
    "\n",
    "    return bases_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_tidel_sensors():\n",
    "\n",
    "    \"\"\"\n",
    "    Returns DataFrames with the information about the sensor and the data.\n",
    "\n",
    "            Parameters:\n",
    "                        None\n",
    "\n",
    "            Returns:\n",
    "                        sensor_information_df (DataFrame): dataframe consisting of:\n",
    "\n",
    "                            e.g.\n",
    "                            NOS ID: 9410170\n",
    "                            Location Name: SAN DIEGO, SAN DIEGO BAY\n",
    "                            Latitude: 32.71419\n",
    "                            Longitude: -117.17358\n",
    "                            Horizontal Datum: WGS-84\n",
    "                            Operator: DOC>NOAA>NOS>CO-OPS\n",
    "                            Vertical Datum: Station Datum\n",
    "\n",
    "                        sensor_data_df (DataFrame): dataframe consisting of the sensor data\n",
    "            Source:\n",
    "                        https://www.ngdc.noaa.gov/hazard/tide/\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating a dictionary to store the metadata and the data\n",
    "    sensor_information_dict = dict()\n",
    "    csv_header = list()\n",
    "    files_in_directory_gz = list()\n",
    "    sensor_data_df = pd.DataFrame()\n",
    "\n",
    "    # Getting all the files in the directory\n",
    "    files_in_directory = os.listdir('./data/tide_sensors')\n",
    "\n",
    "    if len(files_in_directory) == 0:\n",
    "        raise ValueError('No files in the directory')\n",
    "\n",
    "    # Getting all the gz files\n",
    "    for file in files_in_directory:\n",
    "        \n",
    "        # Checking if the file is a gz file\n",
    "        if file.endswith('.gz'):\n",
    "            \n",
    "            # Appending the file to the list\n",
    "            files_in_directory_gz.append(file)\n",
    "\n",
    "    # Looping through all the files in the directory\n",
    "    for idx, file in enumerate(files_in_directory_gz):\n",
    "\n",
    "        # Reading in the file\n",
    "        with gzip.open('./data/tide_sensors/' + file, 'rt') as file_in:\n",
    "            \n",
    "            # Reading in header\n",
    "            sensor_information_file = file_in.readlines()[0:10]\n",
    "\n",
    "        if len(csv_header) == 0:\n",
    "            # Retrieving the header for csv\n",
    "            csv_header = sensor_information_file[-1].removeprefix('// ').removesuffix('\\n').split(',')\n",
    "            csv_header = [item.strip() for item in csv_header]\n",
    "\n",
    "        # Getting metadata for the sensor\n",
    "        for line in sensor_information_file[:-4]:\n",
    "            \n",
    "            name, value = line.removeprefix('// ').strip().split(':')\n",
    "\n",
    "            if name in sensor_information_dict:\n",
    "                sensor_information_dict[name].append(value)\n",
    "            else :\n",
    "                sensor_information_dict[name] = [value]\n",
    "        \n",
    "        # Reading in the data of the sensor\n",
    "        sensor_data_df_temp = pd.read_csv('./data/tide_sensors/' + file, skiprows=10, sep='\\t', header=None, usecols=[0,1])\n",
    "        sensor_data_df_temp.columns = csv_header[:2]\n",
    "        sensor_data_df_temp['NOS ID'] = int(sensor_information_dict.get('NOS ID')[idx])\n",
    "        sensor_data_df_temp['datetime [ISO8601]'] = pd.to_datetime(sensor_data_df_temp['datetime [ISO8601]'], format='ISO8601')\n",
    "        sensor_data_df = pd.concat([sensor_data_df, sensor_data_df_temp])\n",
    "\n",
    "    # Creating a df from the metadata\n",
    "    sensor_information_df = pd.DataFrame(sensor_information_dict)\n",
    "\n",
    "    sensor_information_df = sensor_information_df.assign(geoPoint = list(zip(sensor_information_df.Latitude.astype('float64'), sensor_information_df.Longitude.astype('float64'))))\n",
    "    sensor_information_df.drop(columns = ['Latitude', 'Longitude'], inplace =  True)\n",
    "\n",
    "    return sensor_information_df, sensor_data_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_tide_sensor_data(tide_sensor_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Curates the tide sensor data.\n",
    "\n",
    "            Parameters:\n",
    "                        tide_sensor_df (DataFrame): Contains all read in tide sensors\n",
    "\n",
    "            Returns:\n",
    "                        curated_tide_sensor_df \n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all rows with '9999'\n",
    "    tide_sensor_df = tide_sensor_df[tide_sensor_df['waterlevel_quality_controlled [m]'] != 9999]\n",
    "\n",
    "    # find unique sensors IDs\n",
    "    tide_sensors = tide_sensor_df['NOS ID'].unique()\n",
    "\n",
    "    # Group by NOS ID and month\n",
    "    curated_tide_sensor_mean_df = tide_sensor_df.groupby(['NOS ID', pd.Grouper(key='datetime [ISO8601]', freq='W')])['waterlevel_quality_controlled [m]'].mean()\n",
    "    curated_tide_sensor_min_df = tide_sensor_df.groupby(['NOS ID', pd.Grouper(key='datetime [ISO8601]', freq='W')])['waterlevel_quality_controlled [m]'].min()\n",
    "    curated_tide_sensor_max_df = tide_sensor_df.groupby(['NOS ID', pd.Grouper(key='datetime [ISO8601]', freq='W')])['waterlevel_quality_controlled [m]'].max()\n",
    "\n",
    "    # Reset index\n",
    "    curated_tide_sensor_mean_df = curated_tide_sensor_mean_df.reset_index()\n",
    "    curated_tide_sensor_min_df = curated_tide_sensor_min_df.reset_index()\n",
    "    curated_tide_sensor_max_df = curated_tide_sensor_max_df.reset_index()\n",
    "\n",
    "    # Save Base names for chosen sensors\n",
    "    # must become dynamic!\n",
    "    base_names_for_sensors = ['MCB Hawaii, Kaneohe Bay', 'VSTA San Diego', 'MCB Camp Pendleton', 'NAVSUPDET Monterey (NPS)', 'NAVSTA Everett, Washington']\n",
    "\n",
    "    for idx, sensor in enumerate(tide_sensors):\n",
    "\n",
    "        # Get the sensor data\n",
    "        sensor_data = curated_tide_sensor_mean_df[curated_tide_sensor_mean_df['NOS ID'] == sensor]\n",
    "\n",
    "        # Get the min and max\n",
    "        sensor_data_min = curated_tide_sensor_min_df[curated_tide_sensor_min_df['NOS ID'] == sensor]\n",
    "        sensor_data_max = curated_tide_sensor_max_df[curated_tide_sensor_max_df['NOS ID'] == sensor]\n",
    "\n",
    "        # Merge the data\n",
    "        sensor_data = sensor_data.merge(sensor_data_min[['datetime [ISO8601]', 'waterlevel_quality_controlled [m]']], on='datetime [ISO8601]')\n",
    "        sensor_data = sensor_data.merge(sensor_data_max[['datetime [ISO8601]', 'waterlevel_quality_controlled [m]']], on='datetime [ISO8601]')\n",
    "\n",
    "        # Rename columns\n",
    "        sensor_data.columns = ['NOS ID', 'datetime', 'mean', 'min', 'max']\n",
    "\n",
    "        # Plotting min, mean, and max\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['min'], label='Min')\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['mean'], label='Mean')\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['max'], label='Max')\n",
    "\n",
    "        # Running average\n",
    "        sensor_data['ra_min'] = sensor_data['min'].rolling(window=52).mean()\n",
    "        sensor_data['ra_mean'] = sensor_data['mean'].rolling(window=52).mean()\n",
    "        sensor_data['ra_max'] = sensor_data['max'].rolling(window=52).mean()\n",
    "\n",
    "        # Plotting running average\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['ra_min'], 'r', label='Running average min')\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['ra_mean'], 'r', label='Running average mean')\n",
    "        ax.plot(sensor_data['datetime'], sensor_data['ra_max'], 'r', label='Running average max')\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Water Level (m)')\n",
    "        ax.set_title(f'Tide Sensor {sensor} - {base_names_for_sensors[idx]}')\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "\n",
    "        # Save the plot as an image file\n",
    "        fig.savefig('./plots/plot_' + str(sensor) + '.png')\n",
    "        \n",
    "        #plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(bases_df, sensors_df):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates a map with folium.\n",
    "\n",
    "            Parameters:\n",
    "                        bases_df (DataFrame): Contains all US Bases that we want to see in the Map\n",
    "                        sensors_df (DataFrame): Contains all Sensors that we want to see in the Map\n",
    "\n",
    "            Returns:\n",
    "                        None: \n",
    "    \"\"\"\n",
    "\n",
    "    # folium Map centered on Glasgow Hall\n",
    "    nps_lat = 36.598802\n",
    "    nps_lon = -121.877178\n",
    "\n",
    "    # Create a map object\n",
    "    # Specify center location, and starting zoom level (0 to 18)\n",
    "    map = folium.Map(location=[nps_lat, nps_lon], zoom_start = 4, control_scal = True, tiles = \"Cartodb Positron\")\n",
    "\n",
    "    # Add a marker for Glasgow Hall\n",
    "    coord_list_bases = bases_df['geoPoint']\n",
    "    coord_list_sensors = sensors_df['geoPoint']\n",
    "\n",
    "    # Create a MarkerCluster object for bases & sensors\n",
    "    marker_cluster_bases = MarkerCluster(name='US Bases').add_to(map)\n",
    "    marker_cluster_sensors = MarkerCluster(name='Tidal Sensors').add_to(map)\n",
    "\n",
    "    # Create popups\n",
    "    popups_bases = ['<b>Base:</b><br>{}<br><b>Altitude:</b><br>{}'.format(name, elevation) for (name, elevation) in bases_df[['name', 'elevation']].values]\n",
    "    popups_sensors = ['<b>Name:</b><br>{}'.format(name) for (name) in sensors_df['Location Name'].values]\n",
    "\n",
    "    # Add markers to the MarkerCluster bases\n",
    "    for coord, popup in zip(coord_list_bases, popups_bases):\n",
    "        folium.Marker(location=coord, \n",
    "                      popup=popup, \n",
    "                      icon=folium.Icon('red')).add_to(marker_cluster_bases)\n",
    "        \n",
    "    # Add markers to the MarkerCluster sensors\n",
    "    for sensor, popup in zip(coord_list_sensors, popups_sensors):\n",
    "        folium.Marker(location=sensor, \n",
    "                      popup=popup, \n",
    "                      icon=folium.Icon('blue')).add_to(marker_cluster_sensors)\n",
    "\n",
    "    # Add MarkerCluster to map\n",
    "    marker_cluster_bases.add_to(map)\n",
    "    marker_cluster_sensors.add_to(map)\n",
    "\n",
    "    folium.LayerControl().add_to(map)\n",
    "\n",
    "    # Save the map    \n",
    "    map.save('harborTide.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# east_coast = [\"Alabama\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Minnesota\", \"Mississippi\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New York\", \"Oklahoma\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"Texas\", \"Virginia\", \"Virgin Islands\"]\n",
    "west_coast = [\"Alaska\", \"California\", \"Guam\", \"Hawaii\", \"Oregon\", \"Washington\"]\n",
    "\n",
    "# import military bases\n",
    "bases_df = data_import_bases(west_coast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing sensor information and data\n",
    "tide_sensors_df, tide_sensor_data_df = data_import_tidel_sensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curating and processing the data and creating plots\n",
    "curate_tide_sensor_data(tide_sensor_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a map\n",
    "create_map(bases_df, tide_sensors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
