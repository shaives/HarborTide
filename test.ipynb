{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_bases(stats = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District \", \"of Columbia\", \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a cleaned dataframe with all the military installations.\n",
    "\n",
    "            Parameters:\n",
    "                        states (list): list of stats you want to see bases off\n",
    "\n",
    "            Data:\n",
    "                        https://public.opendatasoft.com/explore/dataset/military-bases/export/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6Im1pbGl0YXJ5LWJhc2VzIiwib3B0aW9ucyI6e319LCJjaGFydHMiOlt7ImFsaWduTW9udGgiOnRydWUsInR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQVZHIiwieUF4aXMiOiJvYmplY3RpZF8xIiwic2NpZW50aWZpY0Rpc3BsYXkiOnRydWUsImNvbG9yIjoiI0ZGNTE1QSJ9XSwieEF4aXMiOiJjb21wb25lbnQiLCJtYXhwb2ludHMiOjUwLCJzb3J0IjoiIn1dLCJ0aW1lc2NhbGUiOiIiLCJkaXNwbGF5TGVnZW5kIjp0cnVlLCJhbGlnbk1vbnRoIjp0cnVlfQ%3D%3D&location=6,37.78808,-111.09375&basemap=jawg.light\n",
    "\n",
    "            Returns:\n",
    "                        bases_df (DataFrame): \n",
    "    \"\"\"\n",
    "\n",
    "    # Choose columns we need\n",
    "    data_columns = ['Geo Point', 'COMPONENT', 'Site Name', 'State Terr', 'Oper Stat']\n",
    "\n",
    "    # read in alle the military bases - seperator ';'\n",
    "    bases_df = pd.read_csv('./data/military-bases.csv', sep=';', usecols = data_columns )\n",
    "\n",
    "    # rename columns for easier use\n",
    "    bases_df.rename(columns={'Geo Point': 'geoPoint', 'COMPONENT': \"component\", 'Site Name': 'name', 'State Terr': 'state', 'Oper Stat': 'status'}, inplace = True)\n",
    "\n",
    "    # checking it there is only Active and Inaktive\n",
    "    #bases_df[(bases_df.status != 'Active') & (bases_df.status != 'Inactive')]\n",
    "\n",
    "    # drop all Inaktive bases\n",
    "    bases_df = bases_df[bases_df.status != 'Inactive']\n",
    "\n",
    "    # convert geo points\n",
    "    bases_df[['lat', 'lon']] = bases_df.geoPoint.str.split(',', expand = True).astype('float64')\n",
    "    bases_df.geoPoint = list(zip(bases_df.lat, bases_df.lon))\n",
    "    bases_df.drop(columns = ['lat', 'lon'], inplace =  True)\n",
    "\n",
    "    # filter by list\n",
    "\n",
    "    bases_df = bases_df[bases_df.state.isin(stats)]\n",
    "\n",
    "    return bases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_coast = [\"Alaska\", \"California\", \"Guam\", \"Hawaii\", \"Oregon\", \"Washington\"]\n",
    "\n",
    "data_import_bases(west_coast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_coast = [\"Alaska\", \"California\", \"Guam\", \"Hawaii\", \"Oregon\", \"Washington\"]\n",
    "data_df = data_import_bases(west_coast)\n",
    "\n",
    "# folium Map centered on Glasgow Hall\n",
    "nps_lat = 36.598802\n",
    "nps_lon = -121.877178\n",
    "\n",
    "# Create a map object\n",
    "# Specify center location, and starting zoom level (0 to 18)\n",
    "map = folium.Map(location=[nps_lat, nps_lon], zoom_start = 4, control_scal = True, tiles = \"Cartodb Positron\")\n",
    "\n",
    "coord_list = data_df.geoPoint\n",
    "\n",
    "popups = ['<b>Base:</b><br>{}<br><b>Altitude:</b><br>{}'.format(name, 'Null') for (name) in data_df.name.values]\n",
    "\n",
    "marker_cluster = MarkerCluster(\n",
    "    locations = coord_list,\n",
    "    popups = popups,\n",
    "    name='US Bases & Tide-sensors',\n",
    "    overlay=True,\n",
    "    control=True\n",
    ")\n",
    "\n",
    "marker_cluster.add_to(map)\n",
    "\n",
    "folium.LayerControl().add_to(map)\n",
    "    \n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./data/tide_sensors/.'):\n",
    "\n",
    "    sensors = dict()\n",
    "\n",
    "    with gzip.open('./data/tide_sensors/' + file, 'rt') as file_in:\n",
    "        \n",
    "        # Reading in header\n",
    "        sensor_information_file = file_in.readlines()[0:10]\n",
    "\n",
    "        sensor_information_dict = dict()\n",
    "\n",
    "        for idx, line in enumerate(sensor_information_file[:-3]):\n",
    "            \n",
    "            key, value = line.removeprefix('// ').split(':')\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "\n",
    "            sensor_information_dict[key] = value\n",
    "\n",
    "        print(sensor_information_dict)\n",
    "\n",
    "        # Reading in data\n",
    "        csv_header = sensor_information_file[-1].removeprefix('// ').split(',')\n",
    "\n",
    "    sensor_data = pd.read_csv('./data/tide_sensors/' + file, skiprows=10, sep='\\t', header=None)\n",
    "    sensor_data.columns = csv_header\n",
    "\n",
    "    sensors[sensor_information_dict.get('NOS ID')] = {'Info' : sensor_information_dict, 'Data' : sensor_data}\n",
    "\n",
    "    print(sensors)\n",
    "\n",
    "    break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/tide_sensors/' + file, skiprows=10, sep='\\t', header=None)\n",
    "data.columns = csv_header\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_information_dict = dict()\n",
    "csv_header = list()\n",
    "sensor_data_df = pd.DataFrame()\n",
    "\n",
    "for idx, file in enumerate(os.listdir('./data/tide_sensors/.')):\n",
    "\n",
    "    with gzip.open('./data/tide_sensors/' + file, 'rt') as file_in:\n",
    "        \n",
    "        # Reading in header\n",
    "        sensor_information_file = file_in.readlines()[0:10]\n",
    "\n",
    "    if len(csv_header) == 0:\n",
    "        # Retrieving the header for csv\n",
    "        csv_header = sensor_information_file[-1].removeprefix('// ').split(',')\n",
    "\n",
    "    # Getting metadata for the sensor\n",
    "    for line in sensor_information_file[:-4]:\n",
    "        \n",
    "        name, value = line.removeprefix('// ').strip().split(':')\n",
    "\n",
    "        if name in sensor_information_dict:\n",
    "            sensor_information_dict[name].append(value)\n",
    "        else :\n",
    "            sensor_information_dict[name] = [value]\n",
    "\n",
    "    sensor_data_df_temp = pd.read_csv('./data/tide_sensors/' + file, skiprows=10, sep='\\t', header=None)\n",
    "    sensor_data_df_temp.columns = csv_header\n",
    "    sensor_data_df_temp['NOS ID'] = sensor_information_dict.get('NOS ID')[idx]\n",
    "    sensor_data_df = pd.concat([sensor_data_df, sensor_data_df_temp])\n",
    "\n",
    "# Creating a df from the metadata\n",
    "sensor_information_df = pd.DataFrame(sensor_information_dict)\n",
    "\n",
    "sensor_information_df = sensor_information_df.assign(geoPoint = list(zip(sensor_information_df.Latitude.astype('float64'), sensor_information_df.Longitude.astype('float64'))))\n",
    "sensor_information_df.drop(columns = ['Latitude', 'Longitude'], inplace =  True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOS ID</th>\n",
       "      <th>Location Name</th>\n",
       "      <th>Horizontal Datum</th>\n",
       "      <th>Operator</th>\n",
       "      <th>geoPoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9410170</td>\n",
       "      <td>SAN DIEGO, SAN DIEGO BAY</td>\n",
       "      <td>WGS-84</td>\n",
       "      <td>DOC&gt;NOAA&gt;NOS&gt;CO-OPS</td>\n",
       "      <td>(32.71419, -117.17358)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9410660</td>\n",
       "      <td>LOS ANGELES, OUTER HARBOR</td>\n",
       "      <td>WGS-84</td>\n",
       "      <td>DOC&gt;NOAA&gt;NOS&gt;CO-OPS</td>\n",
       "      <td>(33.72, -118.272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9414523</td>\n",
       "      <td>REDWOOD CITY, WHARF 5, S. F. BAY</td>\n",
       "      <td>WGS-84</td>\n",
       "      <td>DOC&gt;NOAA&gt;NOS&gt;CO-OPS</td>\n",
       "      <td>(37.50669, -122.20999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9446484</td>\n",
       "      <td>TACOMA, COMMENCEMENT BAY</td>\n",
       "      <td>WGS-84</td>\n",
       "      <td>DOC&gt;NOAA&gt;NOS&gt;CO-OPS</td>\n",
       "      <td>(47.26667, -122.41333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9447130</td>\n",
       "      <td>SEATTLE, PUGET SOUND</td>\n",
       "      <td>WGS-84</td>\n",
       "      <td>DOC&gt;NOAA&gt;NOS&gt;CO-OPS</td>\n",
       "      <td>(47.60263, -122.3393)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NOS ID                      Location Name Horizontal Datum  \\\n",
       "0   9410170           SAN DIEGO, SAN DIEGO BAY           WGS-84   \n",
       "1   9410660          LOS ANGELES, OUTER HARBOR           WGS-84   \n",
       "2   9414523   REDWOOD CITY, WHARF 5, S. F. BAY           WGS-84   \n",
       "3   9446484           TACOMA, COMMENCEMENT BAY           WGS-84   \n",
       "4   9447130               SEATTLE, PUGET SOUND           WGS-84   \n",
       "\n",
       "               Operator                geoPoint  \n",
       "0   DOC>NOAA>NOS>CO-OPS  (32.71419, -117.17358)  \n",
       "1   DOC>NOAA>NOS>CO-OPS       (33.72, -118.272)  \n",
       "2   DOC>NOAA>NOS>CO-OPS  (37.50669, -122.20999)  \n",
       "3   DOC>NOAA>NOS>CO-OPS  (47.26667, -122.41333)  \n",
       "4   DOC>NOAA>NOS>CO-OPS   (47.60263, -122.3393)  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_information_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime [ISO8601]</th>\n",
       "      <th>waterlevel_quality_controlled [m]</th>\n",
       "      <th>waterlevel_modelled [m]</th>\n",
       "      <th>waterlevel_residual [m]\\n</th>\n",
       "      <th>NOS ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01T00:00:00Z</td>\n",
       "      <td>2.004</td>\n",
       "      <td>2.1286</td>\n",
       "      <td>-0.1246</td>\n",
       "      <td>9410170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01T00:01:00Z</td>\n",
       "      <td>2.018</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-0.1101</td>\n",
       "      <td>9410170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01T00:02:00Z</td>\n",
       "      <td>2.031</td>\n",
       "      <td>2.1275</td>\n",
       "      <td>-0.0965</td>\n",
       "      <td>9410170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01T00:03:00Z</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.1270</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>9410170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01T00:04:00Z</td>\n",
       "      <td>2.022</td>\n",
       "      <td>2.1264</td>\n",
       "      <td>-0.1044</td>\n",
       "      <td>9410170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime [ISO8601]   waterlevel_quality_controlled [m]  \\\n",
       "0  2008-01-01T00:00:00Z                               2.004   \n",
       "1  2008-01-01T00:01:00Z                               2.018   \n",
       "2  2008-01-01T00:02:00Z                               2.031   \n",
       "3  2008-01-01T00:03:00Z                               2.021   \n",
       "4  2008-01-01T00:04:00Z                               2.022   \n",
       "\n",
       "    waterlevel_modelled [m]   waterlevel_residual [m]\\n    NOS ID  \n",
       "0                    2.1286                     -0.1246   9410170  \n",
       "1                    2.1281                     -0.1101   9410170  \n",
       "2                    2.1275                     -0.0965   9410170  \n",
       "3                    2.1270                     -0.1060   9410170  \n",
       "4                    2.1264                     -0.1044   9410170  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data_df.head()\n",
    "\n",
    "#sensor_data_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39702563"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sensor_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
